{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SurAyPosStrAdvWMD vs strSurAyPos"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataGrabSurAyPosStr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args in str init:  stri:  Tgy flt:  strTyp: None frm: None poSp: None inpLng: None inpSch: None\n",
      "props set in str init:  stri:  Tgy flt:  strTyp: All frm: All poSp: All inpLng: arabic inpSch: buckwalter_Scheme\n",
      "True\n",
      "طغي All All  All False arb bkwSch\n",
      "time taken for loading strSurAyPos: 0.18190813064575195 39\n"
     ]
    }
   ],
   "source": [
    "from qChronolyze import arbVwlsDict, strTypD, poSpD, lngD, inpLngSchD, rtTrns, remVwls\n",
    "def dataGrabSurAyPosStr(strObj):\n",
    "    flt = str(strObj.flt).lower()\n",
    "    frm = strObj.frm\n",
    "    strTyp = strObj.strTyp if strObj.strTyp in strTypD.values() else strTypD[strObj.strTyp]\n",
    "    poSp = strObj.poSp if strObj.poSp in poSpD.values() else poSpD[strObj.poSp]\n",
    "    inpLng = strObj.inpLng if strObj.inpLng in lngD.values() else lngD[strObj.inpLng]\n",
    "    inpSch = strObj.inpSch if strObj.inpSch in inpLngSchD.values() else inpLngSchD[strObj.inpSch]\n",
    "    stri = rtTrns(strObj.stri,inpLng,inpSch,) if inpLng == \"arb\" else strObj.stri.lower() if inpLng == 'eng' else strObj.stri\n",
    "    isNotRoot = True if (any(char in stri for char in arbVwlsDict.values()) and inpLng == \"arb\" ) else False\n",
    "\n",
    "    print(stri,strTyp,frm,flt,poSp,isNotRoot,inpLng,inpSch)\n",
    "\n",
    "    instLst = []\n",
    "    import re\n",
    "\n",
    "    def poSpOnward(inst,wrdStrD,strD,poSp,frm,flt):\n",
    "        if strD[\"poSp\"] == \"All\" or poSp == \"All\" or strD[\"poSp\"] == poSp:\n",
    "            if strD[\"frm\"] == \"All\" or frm == \"All\" or strD[\"frm\"] == frm:\n",
    "                if ( \n",
    "                    len(\n",
    "                        re.compile(str(flt)).findall(\n",
    "                            wrdStrD[\"mean\"].lower()\n",
    "                        )\n",
    "                    ) > 0 \n",
    "                    or len(\n",
    "                        re.compile(str(stri)).findall(\n",
    "                            wrdStrD[\"mean\"].lower()\n",
    "                        ) \n",
    "                    ) > 0 \n",
    "                ):\n",
    "                    if pos not in inst[2]:\n",
    "                        inst[2].append(pos)\n",
    "                    # inst[3].append(mean)\n",
    "                        \n",
    "    for sur, ayD in surAyPosStrAdvWrdMD.items():\n",
    "        for ay, posD in ayD.items():\n",
    "            # surAy = \":\".join([sur,ay])\n",
    "            inst = [sur,ay,[]]\n",
    "\n",
    "            for pos, wrdStrD in posD.items():\n",
    "                # mean = wrdStrD[\"mean\"]\n",
    "                \n",
    "                if strTyp == \"stem\":\n",
    "                    for strD in wrdStrD[\"striDLs\"]:\n",
    "\n",
    "                        if remVwls(strD[\"stri\"]) in remVwls(stri):\n",
    "                            # poSpOnward(instD,wrdStrD,strD,poSp,frm,flt)\n",
    "                            poSpOnward(inst,wrdStrD,strD,poSp,frm,flt)\n",
    "\n",
    "                        elif remVwls(wrdStrD[\"wrd\"]) in remVwls(stri):\n",
    "                            if strD[\"poSp\"] == \"All\" or poSp == \"All\":\n",
    "                                if strD[\"frm\"] == \"All\" or frm == \"All\":\n",
    "                                    if ( \n",
    "                                        len(\n",
    "                                            re.compile(str(flt)).findall(\n",
    "                                                wrdStrD[\"mean\"].lower()\n",
    "                                            )\n",
    "                                        ) > 0 \n",
    "                                        or len(\n",
    "                                            re.compile(str(stri)).findall(\n",
    "                                                wrdStrD[\"mean\"].lower()\n",
    "                                            ) \n",
    "                                        ) > 0 \n",
    "                                    ):\n",
    "                                        if pos not in inst[2]:\n",
    "                                            inst[2].append(pos)\n",
    "                    \n",
    "                     \n",
    "                else:\n",
    "                    for strD in wrdStrD[\"striDLs\"]:\n",
    "                        # print(strD[\"stri\"],stri)\n",
    "                        if strD[\"stri\"] == stri:\n",
    "                            if strD[\"strTyp\"] == \"All\" or strTyp == 'All' or strD[\"strTyp\"] == strTyp:\n",
    "                                if not (strD[\"strTyp\"] == 'root' and strTyp == 'All' and isNotRoot == True):\n",
    "                                    poSpOnward(inst,wrdStrD,strD,poSp,frm,flt)\n",
    "\n",
    "            \n",
    "            if len(inst[2]) > 0:\n",
    "                instLst.append(inst)\n",
    "\n",
    "    return instLst\n",
    "\n",
    "from time import time\n",
    "from qChronolyze import strObjClass\n",
    "timeStartSurAyPosStrAdvWMD = time()\n",
    "\n",
    "# import re\n",
    "# import csv\n",
    "import json\n",
    "flPth='data/surAyPosStrAdvWrdMD.json'\n",
    "with open(flPth) as f:\n",
    "    surAyPosStrAdvWrdMD = json.loads(f.read())\n",
    "\n",
    "instLsSur = dataGrabSurAyPosStr(\n",
    "    strObjClass(stri=\"Tgy\")\n",
    ")\n",
    "timeEndSurAyPosStrAdvWMD = time()\n",
    "timeLoadSurAyPosStrAdvWMD = timeEndSurAyPosStrAdvWMD - timeStartSurAyPosStrAdvWMD\n",
    "\n",
    "print('time taken for loading strSurAyPos:',timeLoadSurAyPosStrAdvWMD, len(instLsSur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# dataGrabStrSurAyPos"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "args in str init:  stri:  Tgy flt:  strTyp: root frm: None poSp: None inpLng: None inpSch: None\n",
      "props set in str init:  stri:  Tgy flt:  strTyp: root frm: All poSp: All inpLng: arabic inpSch: buckwalter_Scheme\n",
      "True\n",
      "طغي طغي\n",
      "time taken for loading strSurAyPos: 0.5230200290679932 39\n"
     ]
    }
   ],
   "source": [
    "from qChronolyze import arbVwlsDict, strTypD, poSpD, lngD, inpLngSchD, rtTrns, remVwls\n",
    "def dataGrabStrSurAyPos(strObj):\n",
    "    import re\n",
    "    flt = str(strObj.flt).lower()\n",
    "    frm = strObj.frm\n",
    "    strTyp = strObj.strTyp if strObj.strTyp in strTypD.values() else strTypD[strObj.strTyp]\n",
    "    poSp = strObj.poSp if strObj.poSp in poSpD.values() else poSpD[strObj.poSp]\n",
    "    inpLng = strObj.inpLng if strObj.inpLng in lngD.values() else lngD[strObj.inpLng]\n",
    "    inpSch = strObj.inpSch if strObj.inpSch in inpLngSchD.values() else inpLngSchD[strObj.inpSch]\n",
    "    # stri = strObj.stri\n",
    "    stri = rtTrns(strObj.stri,inpLng,inpSch,) if inpLng == \"arb\" else strObj.stri.lower() if inpLng == 'eng' else strObj.stri\n",
    "    isRoot = False if (any(char in stri for char in arbVwlsDict.values()) and inpLng == \"arb\" ) else True\n",
    "    \n",
    "    # print(stri,strTyp,frm,flt,poSp,isNotRoot,inpLng,inpSch)\n",
    "\n",
    "    instLst = []\n",
    "    instD = {}\n",
    "\n",
    "    # def insDMk(prev,ls,strArg,meanArg,instDArg={}):\n",
    "    def insDMk(prev,ls,instDArg={}):\n",
    "\n",
    "        def poSpMatch(posDL,instDArg2,):\n",
    "            for wrdStrD in posDL:\n",
    "                curStri = wrdStrD[\"wrd\"]\n",
    "                curMean = wrdStrD[\"mean\"]\n",
    "                surAyPos = wrdStrD[\"surAyPos\"]\n",
    "                # print(surAyPos)\n",
    "                sur,ay,pos = surAyPos\n",
    "                surAy = \":\".join([sur,ay])\n",
    "                if ( \n",
    "                    len(\n",
    "                        re.compile(str(flt)).findall(\n",
    "                            wrdStrD[\"mean\"].lower()\n",
    "                        )\n",
    "                    ) > 0 \n",
    "                    or len(\n",
    "                        re.compile(str(stri)).findall(\n",
    "                            wrdStrD[\"mean\"].lower()\n",
    "                        ) \n",
    "                    ) > 0 \n",
    "                ):\n",
    "                    if surAy not in instDArg2:\n",
    "                        instDArg2[surAy] = [pos]\n",
    "                    else:\n",
    "                        if pos not in instDArg2[surAy]:\n",
    "                            instDArg2[surAy].append(pos)\n",
    "\n",
    "            # print(instDArg2)\n",
    "            return instDArg2\n",
    "\n",
    "\n",
    "        for k in ls:\n",
    "            if len(ls) == 1:\n",
    "                poSp = ls[0]\n",
    "                # print(poSp)\n",
    "                if poSp == 'All':\n",
    "                    for poSpK in prev.keys():\n",
    "                        instDArg = poSpMatch(prev[poSpK],instDArg,)\n",
    "                else:\n",
    "                    instDArg = poSpMatch(prev[k],instDArg,)\n",
    "            else:\n",
    "                if k != 'All':\n",
    "                    instDArg = insDMk(prev[k],ls[1:],instDArg)\n",
    "                else:\n",
    "                    for k2 in prev.keys():\n",
    "                        instDArg = insDMk(prev[k2],ls[1:],instDArg)\n",
    "\n",
    "        # print(instDArg)\n",
    "        return instDArg\n",
    "\n",
    "                \n",
    "    if strTyp == \"stem\" or strTyp == 'All':\n",
    "\n",
    "        if isRoot:\n",
    "            for root in striSuAyPosWMD[\"root\"]:\n",
    "                if root in remVwls(stri):\n",
    "                    # print(root,stri)\n",
    "                    instD = insDMk(striSuAyPosWMD[\"root\"][root],[frm,poSp],instD)\n",
    "                    # print(instD)\n",
    "                    break\n",
    "        else:\n",
    "            for stem in striSuAyPosWMD[\"stem\"]:\n",
    "                if remVwls(stem) in remVwls(stri):\n",
    "                    instD = insDMk(striSuAyPosWMD[\"stem\"][stem],[frm,poSp],instD)\n",
    "                    break\n",
    "                    # poSpOnward(instD,wrdStrD,strD,poSp,frm,flt)\n",
    "\n",
    "            for lem in striSuAyPosWMD[\"lem\"]:\n",
    "                if remVwls(lem) in remVwls(stri):\n",
    "                    instD = insDMk(striSuAyPosWMD[\"lem\"][lem],[frm,poSp],instD)\n",
    "                    break\n",
    "\n",
    "    \n",
    "    else:\n",
    "        for curStri in striSuAyPosWMD[strTyp]:\n",
    "            if curStri == stri:\n",
    "                print(curStri,stri)\n",
    "                instD = insDMk(striSuAyPosWMD[strTyp][stri],[frm,poSp],instD)\n",
    "                break\n",
    "\n",
    "\n",
    "    instLst = [\n",
    "        [sur2,ay2,poss]\n",
    "        for surAy, poss in instD.items()\n",
    "        for sur2,ay2 in [surAy.split(':')]\n",
    "    ]\n",
    "\n",
    "    # print(\"instLst in dataGrabber\", instLst)\n",
    "    return instLst\n",
    "    # return instD\n",
    "\n",
    "from time import time\n",
    "from qChronolyze import strObjClass\n",
    "timeStartStrSurAyPos = time()\n",
    "\n",
    "# import re\n",
    "# import csv\n",
    "# import json\n",
    "# flPth='data/surAyPosStrAdvWrdMD.json'\n",
    "# # list_header=[\"surah\",\"ayah\",\"position\",\"word\",\"strings_dictionary\"]\n",
    "# with open(flPth) as f:\n",
    "#     surAyPosStrAdvWrdMD = json.loads(f.read())\n",
    "# #     surAyPosStrAdvWrdMDRws = list(csv.DictReader(f, delimiter='\\t'))\n",
    "# surAyPosStrAdvWrdMD = {\n",
    "# }\n",
    "# for surAyPosStrAdvWrd in surAyPosStrAdvWrdMDRws:\n",
    "#     [sur, ay, pos, stri, mean, strDLs ] = surAyPosStrAdvWrd.values()\n",
    "#     # [sur,ay,pos] = surAyPos.split(':')\n",
    "#     if sur not in surAyPosStrAdvWrdMD:\n",
    "#         surAyPosStrAdvWrdMD[sur] = {}\n",
    "#     if ay not in surAyPosStrAdvWrdMD[sur]:\n",
    "#         surAyPosStrAdvWrdMD[sur][ay] = {}\n",
    "#     # if pos not in surAyPosStrAdvWrdMD[sur][ay]:\n",
    "#     surAyPosStrAdvWrdMD[sur][ay][pos] = {\n",
    "#         # \"wrd\": posD[surAyPos],\n",
    "#         # \"striDLs\": strDLs,\n",
    "#         # \"wrd\": stri,\n",
    "#         # \"striDLs\": posStrAdvDict[surAyPos],\n",
    "#         \"wrd\": stri,\n",
    "#         \"mean\": mean,\n",
    "#         \"striDLs\": json.loads(strDLs),\n",
    "#         # \"striDLs\": posStrAdvDict.get(surAyPos,['problematic pos']),\n",
    "#         # \"striDLs\": posStrAdvDict.get(pos,['problematic pos']),\n",
    "#     }\n",
    "\n",
    "import re\n",
    "import json\n",
    "with open(\"data/striSuAyPosWMD.json\") as f:\n",
    "    striSuAyPosWMD = json.loads(f.read())\n",
    "# striSuAyPosWMD = {}\n",
    "# for surAyPosStrAdvWrd in surAyPosStrAdvWrdMDRws:\n",
    "#     [sur, ay, pos, wrd, mean, strDLs ] = surAyPosStrAdvWrd.values()\n",
    "#     strLs = json.loads(strDLs)\n",
    "#     for strD in strLs:\n",
    "#         stri = strD[\"stri\"]\n",
    "#         strTyp = strD[\"strTyp\"]\n",
    "#         frm = strD[\"frm\"]\n",
    "#         poSp = strD[\"poSp\"]\n",
    "#         if strTyp not in striSuAyPosWMD:\n",
    "#             striSuAyPosWMD[strTyp] = {}\n",
    "#         # else:\n",
    "#         if stri not in striSuAyPosWMD[strTyp]:\n",
    "#             striSuAyPosWMD[strTyp][stri] = {}\n",
    "#         if frm not in striSuAyPosWMD[strTyp][stri]:\n",
    "#             striSuAyPosWMD[strTyp][stri][frm] = {}\n",
    "#         if poSp not in striSuAyPosWMD[strTyp][stri][frm]:\n",
    "#             striSuAyPosWMD[strTyp][stri][frm][poSp] = []\n",
    "#         # posAlready = False\n",
    "#         surAyPos = [sur,ay,pos]\n",
    "#         if surAyPos not in striSuAyPosWMD[strTyp][stri][frm][poSp]:\n",
    "#             striSuAyPosWMD[strTyp][stri][frm][poSp].append({\n",
    "#                 \"surAyPos\": [sur,ay,pos],\n",
    "#                 \"wrd\": wrd,\n",
    "#                 \"mean\": mean\n",
    "#             })\n",
    "#         else:\n",
    "#             pass\n",
    "\n",
    "instLsStr = dataGrabStrSurAyPos(\n",
    "    strObjClass(\n",
    "        stri=\"Tgy\",\n",
    "        strTyp='root'\n",
    "    )\n",
    ")\n",
    "timeEndStrSurAyPos = time()\n",
    "timeLoadstrSurAyPos = timeEndStrSurAyPos - timeStartStrSurAyPos\n",
    "# for inst in instLsStr:\n",
    "#     print(inst)\n",
    "print('time taken for loading strSurAyPos:',timeLoadstrSurAyPos, len(instLsStr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'wrd': 'ٱقْرَأْ',\n",
       " 'mean': 'Read',\n",
       " 'striDLs': [{'stri': 'قرا', 'strTyp': 'root', 'poSp': 'V', 'frm': 'i'}]}"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "surAyPosStrAdvWrdMD[\"96\"][\"1\"][\"1\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading strD is faster than posD by: -187.51877511540306 %\n"
     ]
    }
   ],
   "source": [
    "# timeLoadSurAyPosStrAdvWMD = 0.014032602310180664\n",
    "# timeLoadstrSurAyPos = 0.0004010200500488281\n",
    "print(\"loading strD is faster than posD by:\", (timeLoadSurAyPosStrAdvWMD-timeLoadstrSurAyPos)/timeLoadSurAyPosStrAdvWMD*100, \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from qChronolyze import dataGrabber\n",
    "instLs = dataGrabber(\n",
    "    strObjClass(stri=\"Tgy\",strTyp='root')\n",
    ")\n",
    "for inst in instLs:\n",
    "    print(inst)\n",
    "print( len(instLs))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for inst1 in instLsStr:\n",
    "    if inst1 not in instLs:\n",
    "        print(inst1, 'not in instLs')\n",
    "for inst1 in instLs:\n",
    "    if inst1 not in instLsStr:\n",
    "        print(inst1, 'not in instLstStr')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# json vs tsv speed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qChronolyze import\n",
    "\n",
    "class row2DictCl:\n",
    "    def __init__(\n",
    "            self,surah_ayah='',position='',string='',meaning='',\n",
    "            # ayah_link='',\n",
    "            query=''\n",
    "        ):\n",
    "        self.surah_ayah = surah_ayah\n",
    "        self.position = position\n",
    "        self.string = string\n",
    "        self.meaning = meaning\n",
    "        # self.ayah_link = ayah_link\n",
    "        self.query = query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tblUp(tblCumul,tblAgg,instDct,stri,lnk\n",
    "            #   frm='',ptSp=''\n",
    "                ):\n",
    "        # for tbl in tbls:\n",
    "        #     # print(tbl)\n",
    "        #     tblAgg += tbl\n",
    "\n",
    "        # print(len(tblAgg))\n",
    "        \n",
    "        # print(f\"number of instances of {stri} in {lnk} before Adam filter: {len(tblAgg)}\")\n",
    "\n",
    "        if len(tblAgg) > 0:\n",
    "        # if len(tbls) > 0:\n",
    "            # print(f\"1st row of Table aggregate for {lnk} for {rt} is: {tblAgg[0].find_all('td')}\")\n",
    "            print(tblAgg[0].find_all('td')[1])\n",
    "            if 'adam' in tblAgg[0].find_all('td')[1].get_text().lower():\n",
    "            # if 'adam' in tbls[0].find_all('td')[1].get_text().lower():\n",
    "                if stri.lower() != 'adam' and stri != 'A^dam':\n",
    "                    # print(\"no results\")\n",
    "                    tblAgg = []\n",
    "                    # tbls = []\n",
    "\n",
    "        # print(f\"number of instances of {stri} in {lnk} after Adam filter: {len(tblAgg)}\")\n",
    "        # print(tblAgg)\n",
    "\n",
    "        tblCumul += tblAgg\n",
    "        # tblCumul += tbls\n",
    "\n",
    "        print(\"length of tblCumul: \", len(tblCumul))\n",
    "        # print(f\"total number of instances so far of {rt} without removing duplicates: {len(tblCumul)}\")\n",
    "\n",
    "        for rw in tblCumul:\n",
    "            row = [ fld.get_text() for fld in rw.find_all(\"td\") ]\n",
    "            # row = []\n",
    "            # for fld in rw:\n",
    "            #   row.append(fld.get_text())\n",
    "        \n",
    "            # print(row)\n",
    "            pos = row[0].split(' ')[0].strip('()')\n",
    "            # print(pos)\n",
    "            if pos not in instDct:\n",
    "                # print(posSplit)\n",
    "                posSplit = pos.split(':')\n",
    "                # print(posSplit)\n",
    "                # instLst.append({\n",
    "                instDct[pos] = row2DictCl(\n",
    "                    f'{posSplit[0]}:{posSplit[1]}', \n",
    "                    posSplit[2], \n",
    "                    row[0].split(' ')[1], \n",
    "                    row[1], \n",
    "                    # row[2], \n",
    "                )\n",
    "                # instDct[pos] = {\n",
    "                #         \"surah_ayah\": f'{posSplit[0]}:{posSplit[1]}',\n",
    "                #         #   \"position\": int(posSplit[2]), \n",
    "                #         \"position\": posSplit[2], \n",
    "                #         \"string\": row[0].split(' ')[1], \n",
    "                #         \"meaning\": row[1],\n",
    "                #         # \"form\": frm,\n",
    "                #         # \"p-o-s\": ptSp,\n",
    "                #         \"ayah_link\": row[2]\n",
    "                #     }\n",
    "                # # })\n",
    "        \n",
    "                # poss.add(pos)\n",
    "            else:\n",
    "                # if instDct[pos][\"form\"] == '' and frm != '':\n",
    "                #     instDct[pos][\"form\"] = frm\n",
    "                # if instDct[pos][\"p-o-s\"] == '' and ptSp != '':\n",
    "                #     instDct[pos][\"p-o-s\"] = ptSp\n",
    "                pass\n",
    "\n",
    "            # print(f\"number of unique instances upto {lnk}: {len(poss)} or {len(instLst)}\")\n",
    "            \n",
    "        print(len(tblCumul), len(instDct))\n",
    "        # print(tblAgg)\n",
    "\n",
    "        return tblCumul, instDct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def webGet(stri,lnks,poSp,frm):\n",
    "    # import html2text\n",
    "    # import json\n",
    "    import requests\n",
    "    from bs4 import BeautifulSoup\n",
    "    import re\n",
    "\n",
    "    def getTbl(grabhtmlPara):\n",
    "        soup = BeautifulSoup(\n",
    "            grabhtmlPara,\n",
    "            'lxml' \n",
    "        )\n",
    "\n",
    "        tblsRet = soup.find_all(\n",
    "            \"table\",\n",
    "            {\"class\":\"taf\"}\n",
    "        )\n",
    "\n",
    "        return tblsRet\n",
    "\n",
    "\n",
    "    # poss = set()\n",
    "    instDct={}\n",
    "    tblCumul = []\n",
    "    # tblAgg = []\n",
    "    print(f\"proper data not found for {stri}\")\n",
    "\n",
    "\n",
    "    for lnk in lnks:\n",
    "        print('\\ngetting for link: ', lnk, '\\n')\n",
    "        if lnk == f'https://corpus.quran.com/qurandictionary.jsp?q={stri}':\n",
    "            grabhtml = requests.get(lnk).text\n",
    "            # print(type(grabhtml))\n",
    "\n",
    "            import re\n",
    "\n",
    "            headTbls = re.findall('(<h4 class=\"dxe\">.*?(?=<h4))',grabhtml,re.DOTALL)\n",
    "\n",
    "            # print(len(headTbls))\n",
    "\n",
    "            for headTbl in headTbls:\n",
    "                tblAgg = []\n",
    "                soup = BeautifulSoup(\n",
    "                    headTbl,\n",
    "                    'lxml',\n",
    "                    # 'html.parser',\n",
    "                )\n",
    "                head4 = soup.find_all(\n",
    "                    \"h4\",\n",
    "                    {\"class\":\"dxe\"}\n",
    "                )[0]\n",
    "\n",
    "                # if len(tblsRet) > 0:\n",
    "                    # print(len(tblsRet) > 0)\n",
    "                    # print(len(tblsRet))\n",
    "                    # if len(tblsRet) == len(head4s):\n",
    "                    # print(len(tblsRet) == len(head4s))\n",
    "                # for i in range(len(head4s)):\n",
    "                    # print(head4s[i].text)\n",
    "\n",
    "                tblGrm = head4.text.split('-')[0]\n",
    "                tblForms = re.findall('\\(form (.*?)\\)', tblGrm)\n",
    "                if len(tblForms) == 0:\n",
    "                    tblForm = 'All'\n",
    "                else:\n",
    "                    # print(tempForms[0])\n",
    "                    tblForm = tblForms[0]\n",
    "                tblPoSps = re.findall(f'(^[^\\(\\)]*?(?=\\s*$|\\s*\\())', tblGrm)\n",
    "                if len(tblPoSps) == 0:\n",
    "                    tblPoSp = 'All'\n",
    "                else:\n",
    "                    # print(tempPtSps[0])\n",
    "                    tblPoSp = tblPoSps[0]\n",
    "\n",
    "                if tblForm == 'All':\n",
    "                    if tblPoSp != 'All':\n",
    "                        tblForm = 'I'\n",
    "                print(\n",
    "                    # grm, \n",
    "                    tblForm, \n",
    "                    tblPoSp\n",
    "                )\n",
    "\n",
    "                tbls = soup.find_all(\n",
    "                    \"table\",\n",
    "                    {\"class\":\"taf\"}\n",
    "                )\n",
    "\n",
    "                # tblAgg = [ tbl for tbl in tbls ]\n",
    "\n",
    "                # print(tblsRet)\n",
    "                for tbl in tbls:\n",
    "                    if tblPoSp == poSp and tblForm == frm:\n",
    "                        tblAgg += tbl\n",
    "                print(\"tblAgg length\", len(tblAgg))\n",
    "                tblCumul,instDct = tblUp(tblCumul,tblAgg,instDct,\n",
    "                                        #  tempForm,tempPtSp\n",
    "                                        stri,lnk\n",
    "                                            )\n",
    "\n",
    "\n",
    "        else:\n",
    "            pgs = []\n",
    "            tblAgg = []\n",
    "            grabhtml = requests.get(f\"{lnk}\").text\n",
    "            tbls = getTbl(grabhtml)\n",
    "            if 'Results' in grabhtml:\n",
    "                matches = re.findall(\">[\\n\\s]*Results[\\s\\n]*<b>\\d*</b>[\\s\\n]*to[\\s\\n]*<b>\\d*</b>[\\s\\n]*of[\\s\\n]*<b>(\\d*)</b>\", grabhtml, re.DOTALL)\n",
    "                # print('\\nmatches: ', matches)\n",
    "                if len(matches) > 0:\n",
    "                    pgFlt = int(matches[0])/50\n",
    "                    pgCount = int(pgFlt) + 1 if int(matches[0]) % 50 != 0 else int(pgFlt)\n",
    "                    # print(f\"page count in {lnk} is: {pgCount}\")\n",
    "                    # print(type(pgCount), pgCount)\n",
    "                    pgs = list(map(lambda x : f'&page={x}', list(range(2,pgCount+1))))\n",
    "\n",
    "                for pg in pgs:\n",
    "                    print(f'\\nin pg {pg}')\n",
    "                    grabhtml = requests.get(f\"{lnk}{pg}\").text\n",
    "                    tbls += getTbl(grabhtml)\n",
    "                    # print(f\"length of grabhtml is: {len(grabhtmlNew)}\")\n",
    "                    # grabhtml += grabhtmlNew\n",
    "                    # print(f\"length of grabhtml after adding is: {len(grabhtml)}\")\n",
    "                \n",
    "            for tbl in tbls:\n",
    "                tblAgg += tbl\n",
    "                \n",
    "            print(\"length of tblAgg: \", len(tblAgg))\n",
    "            \n",
    "            tblCumul,instDct = tblUp(tblCumul,tblAgg,instDct,stri,lnk)\n",
    "\n",
    "        # print(f\"\\nnumber of tables found in {lnk} for {rt} is: {len(tbls)}\")\n",
    "        # print(f\"{tbls}\\n\")\n",
    "        return instDct"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = webGet(\"laA\",[\"https://corpus.quran.com/search.jsp?q=stem:laA\"],\"All\",\"All\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileWriteJson(filepath,instDct):\n",
    "    # list_header = ['surah_ayah', 'position', 'string', 'meaning', 'ayah_link'\n",
    "    #             #    'form', 'p-o-s', \n",
    "    #     ]\n",
    "    # print(f\"writing {stri} to '{filepath}'\")\n",
    "        # print(f\"writing {stri} to '{filepath}'\")\n",
    "    import json\n",
    "        # import csv\n",
    "        # writer = csv.DictWriter(f, delimiter='\\t', fieldnames=list_header)\n",
    "        # writer.writeheader()\n",
    "        # for datum in instLst:\n",
    "        # for k, datum in instDct.items():\n",
    "        # for datum in instDct.values():\n",
    "    \n",
    "    instLs = [row[:4] for datum in instDct.values() if (row := list(datum.__dict__.values())) ]\n",
    "            # writer.writerow({\n",
    "            #     # list_header[0] : datum['surah_ayah'],\n",
    "            #     # list_header[1] : datum['position'],\n",
    "            #     # list_header[2] : datum['string'],\n",
    "            #     # list_header[3] : datum['meaning'],\n",
    "            #     # list_header[4] : datum['ayah_link'],\n",
    "            #     list_header[0] : datum.surah_ayah,\n",
    "            #     list_header[1] : datum.position,\n",
    "            #     list_header[2] : datum.string,\n",
    "            #     list_header[3] : datum.meaning,\n",
    "            #     list_header[4] : datum.ayah_link,\n",
    "            #     # list_header[4] : datum['form'],\n",
    "            #     # list_header[5] : datum['p-o-s'],\n",
    "            # })\n",
    "    with open(f'{filepath}', 'w+') as f:\n",
    "        f.write(json.dumps(instLs))\n",
    "    \n",
    "    # return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileWriteTsv(filepath,instDct):\n",
    "    list_header = ['surah_ayah', 'position', 'string', 'meaning', \n",
    "                #    'ayah_link'\n",
    "                #    'form', 'p-o-s', \n",
    "        ]\n",
    "    # print(f\"writing {stri} to '{filepath}'\")\n",
    "    with open(f'{filepath}', 'w+') as f:\n",
    "        # print(f\"writing {stri} to '{filepath}'\")\n",
    "        import csv\n",
    "        writer = csv.DictWriter(f, delimiter='\\t', fieldnames=list_header)\n",
    "        writer.writeheader()\n",
    "        # for datum in instLst:\n",
    "        # for k, datum in instDct.items():\n",
    "        for datum in instDct.values():\n",
    "            writer.writerow({\n",
    "                # list_header[0] : datum['surah_ayah'],\n",
    "                # list_header[1] : datum['position'],\n",
    "                # list_header[2] : datum['string'],\n",
    "                # list_header[3] : datum['meaning'],\n",
    "                # list_header[4] : datum['ayah_link'],\n",
    "                list_header[0] : datum.surah_ayah,\n",
    "                list_header[1] : datum.position,\n",
    "                list_header[2] : datum.string,\n",
    "                list_header[3] : datum.meaning,\n",
    "                # list_header[4] : datum.ayah_link,\n",
    "                # list_header[4] : datum['form'],\n",
    "                # list_header[5] : datum['p-o-s'],\n",
    "            })\n",
    "    \n",
    "    # return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBegin = time.time()\n",
    "fileWriteJson(\"test1.json\",data1)\n",
    "timeEnd = time.time()\n",
    "timeTakenJsonWrite = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "timeBegin = time.time()\n",
    "fileWriteTsv(\"test1.tsv\",data1)\n",
    "timeEnd = time.time()\n",
    "timeTakenTsvWrite = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for writing TSV is faster than json by: -69.59960800783985 %\n"
     ]
    }
   ],
   "source": [
    "print(\"for writing TSV is faster than json by:\", (timeTakenJsonWrite-timeTakenTsvWrite)/timeTakenJsonWrite*100, \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileReadJson(filepath):\n",
    "        list_header = ['surah_ayah', 'position', 'string', 'meaning', \n",
    "                    #    'ayah_link'\n",
    "                #    'form', 'p-o-s', \n",
    "        ]\n",
    "\n",
    "        row_width = len(list_header)\n",
    "\n",
    "        import json\n",
    "        # print(f\"file found for {stri}\")\n",
    "        instDct = {}\n",
    "        # try:\n",
    "        with open(filepath) as f:\n",
    "            # print(f\"loading {filepath}\")\n",
    "            instTbl = json.loads(f.read())\n",
    "        print(len(instTbl))\n",
    "            # instLst = [row for row in csv.DictReader(f, delimiter='\\t') ]\n",
    "        for row in instTbl:\n",
    "            surAyPos = f'{row[0]}:{row[1]}'\n",
    "            # print('for ', surAyPos)\n",
    "            # surAyPos = f'{row[\"surah_ayah\"]}:{row[\"position\"]}'\n",
    "            dicti = {\n",
    "                list_header[i]: row[i]\n",
    "                for i in range(row_width)\n",
    "            }\n",
    "            # instDct[surAyPos] = row\n",
    "            instDct[surAyPos] = row2DictCl(**dicti)\n",
    "            # print(instDct[surAyPos].__dict__)\n",
    "\n",
    "        print(f\"Successfully loaded data from '{filepath}: lenght {len(instDct)}'\")\n",
    "            # propDat = True\n",
    "        # except:\n",
    "        #     # propDat = False\n",
    "        #     instDct = {}\n",
    "        #     print(f\"couldn't load data from '{filepath}': lenght {len(instDct)}\")\n",
    "        \n",
    "        return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def fileReadTsv(filepath):\n",
    "        import csv\n",
    "        # print(f\"file found for {stri}\")\n",
    "        instDct = {}\n",
    "        # try:\n",
    "        with open(filepath) as f:\n",
    "            print(f\"loading {filepath}\")\n",
    "            instTbl = csv.DictReader(f, delimiter='\\t')\n",
    "\n",
    "            # print(len(instTbl))\n",
    "            # instLst = [row for row in csv.DictReader(f, delimiter='\\t') ]\n",
    "            for row in instTbl:\n",
    "                surAyPos = f'{row[\"surah_ayah\"]}:{row[\"position\"]}'\n",
    "                # print('for ', surAyPos)\n",
    "                # surAyPos = f'{row[\"surah_ayah\"]}:{row[\"position\"]}'\n",
    "\n",
    "                # instDct[surAyPos] = row\n",
    "                instDct[surAyPos] = row2DictCl(**row)\n",
    "                # print(instDct[surAyPos].__dict__)\n",
    "\n",
    "            print(f\"Successfully loaded data from '{filepath}: lenght {len(instDct)}'\")\n",
    "            # propDat = True\n",
    "        # except:\n",
    "        #     # propDat = False\n",
    "        #     instDct = {}\n",
    "            # print(f\"couldn't load data from '{filepath}': lenght {len(instDct)}\")\n",
    "        \n",
    "        return instDct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1689\n",
      "Successfully loaded data from 'test1.json: lenght 1689'\n"
     ]
    }
   ],
   "source": [
    "timeBegin = time.time()\n",
    "data1 = fileReadJson(\"test1.json\")\n",
    "timeEnd = time.time()\n",
    "timeTakenJsonRead = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "loading test1.tsv\n",
      "Successfully loaded data from 'test1.tsv: lenght 1689'\n"
     ]
    }
   ],
   "source": [
    "timeBegin = time.time()\n",
    "data2 = fileReadTsv(\"test1.tsv\")\n",
    "timeEnd = time.time()\n",
    "timeTakenTsvRead = timeBegin-timeEnd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "for reading TSV is faster than json by: -19.43990106514541 %\n"
     ]
    }
   ],
   "source": [
    "print(\"for reading TSV is faster than json by:\", (timeTakenJsonRead-timeTakenTsvRead)/timeTakenJsonRead*100, \"%\" )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data1 lenghth == data2 lenght  True\n"
     ]
    }
   ],
   "source": [
    "lenData1 = len(data1)\n",
    "isEqualData = lenData1 == len(data2)\n",
    "print(\"data1 lenghth == data2 lenght \", isEqualData)\n",
    "\n",
    "if isEqualData:\n",
    "    # for i in range(lenData1):\n",
    "    data1Keys = list(data1.keys())\n",
    "    data1Values = list(data1.values())\n",
    "    data2Keys = list(data1.keys())\n",
    "    data2Values = list(data1.values())\n",
    "    for i in range(lenData1):\n",
    "        if data1Keys[i] != data2Keys[i]:\n",
    "            print(f\"for {i} data1 key is {data1Keys[i]} and data2 key is {data2Keys[i]}\")\n",
    "        else:\n",
    "            if data1Values[i].__dict__ != data2Values[i].__dict__:\n",
    "                print(f\"for {i} data1 value is {data1Values[i]} and data2 Value is {data2Values[i]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data2"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
